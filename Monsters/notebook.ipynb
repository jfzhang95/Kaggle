{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport tensorflow as tf\n\nimport itertools\nimport os\nimport tflearn\n\n\nfrom matplotlib import pyplot as plt\nfrom sklearn.decomposition.kernel_pca import KernelPCA\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import PolynomialFeatures",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%matplotlib inline",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\nsubmission = pd.read_csv(\"../input/sample_submission.csv\")\nsubmission[\"type\"] = \"Unknown\"",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# First look at features.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.pairplot(train.drop(\"id\",axis=1), hue=\"type\", diag_kind=\"kde\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The fucking :) Goblins always in the middle.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Feature engineering ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "We will try some combinations to check if we can find a feature where the classes present lees overlap.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# interaction_only to avoid x**2, etc\npoly_features = PolynomialFeatures(interaction_only=True)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# [:,5:] to discard columns of original features\ntry_comb = pd.DataFrame(\n    poly_features.fit_transform(train.drop([\"id\", \"color\", \"type\"], axis=1))[:,5:],\n    columns=[\"boneXrotting\", \"boneXhair\", \"boneXsoul\",\n             \"rottingXhair\", \"rottingXsoul\", \n             \"hairXsoul\"]\n)\ntry_comb[\"type\"] = train.type",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Plot polynomial features",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.pairplot(try_comb, hue=\"type\", diag_kind=\"kde\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Keep:\n\n- bone_length_x_hair_length\n- bone_length_x_has_soul\n- hair_length_x_has_soul",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "for i in [\"boneXhair\", \"boneXsoul\", \"hairXsoul\"]:\n    train[i] = try_comb[i].copy()\ntry_comb = None",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Same for test",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "try_comb = pd.DataFrame(\n    poly_features.fit_transform(test.drop([\"id\", \"color\"], axis=1))[:,5:],\n    columns=[\"boneXrotting\", \"boneXhair\", \"boneXsoul\",\n             \"rottingXhair\", \"rottingXsoul\", \n             \"hairXsoul\"]\n)\n\nfor i in [\"boneXhair\", \"boneXsoul\", \"hairXsoul\"]:\n    test[i] = try_comb[i].copy()\n    \ntry_comb = None",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Get 1vs1 KPCA features",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Try to project all the features using a kernel PCA checking 1vs1 for all the classes.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "train.loc[train.type == \"Ghost\", \"type\"] = 0\ntrain.loc[train.type == \"Ghoul\", \"type\"] = 1\ntrain.loc[train.type == \"Goblin\", \"type\"] = 2\ntrain[\"type\"] = train[\"type\"].astype(\"int\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "is_ghost = (train.type == 0).values\nis_ghoul = (train.type == 1).values\nis_goblin = (train.type == 2).values",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ghost_ghoul = train.loc[is_ghost | is_ghoul].copy()\nghost_goblin = train.loc[is_ghost | is_goblin].copy()\nghoul_goblin = train.loc[is_ghoul| is_goblin].copy()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Helper function to plot the KPCA projection on the 2 principal vectors.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def plot_KPCA(df, transf, labels={\"A\":0, \"B\":1}):\n    plt.figure(figsize=(10,8))\n\n    for label,marker,color in zip(list(labels.keys()),('x', 'o'),('blue', 'red')):\n\n        plt.scatter(x=transf[:,0][(df.type == labels[label]).values],\n                    y=transf[:,1][(df.type == labels[label]).values],\n                    marker=marker,\n                    color=color,\n                    alpha=0.7,\n                    label='class {}'.format(label)\n                    )\n\n    plt.legend()\n    plt.title('KernelPCA projection')\n\n    plt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Ghost - Ghoul",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = ghost_ghoul.drop([\"id\", \"color\", \"type\"], axis=1).values\ny = ghost_ghoul.type.values\n\nKPCA = KernelPCA(n_components=2, kernel=\"rbf\", gamma=1)\nghost_ghoul_KPCA= KPCA.fit(X,y)\n\nghost_ghoul_transf = ghost_ghoul_KPCA.transform(X)\n\nplot_KPCA(ghost_ghoul, ghost_ghoul_transf, labels={\"Ghost\":0, \"Ghoul\":1})",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Nice visual separation yee!",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Ghost - Goblin",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = ghost_goblin.drop([\"id\", \"color\", \"type\"], axis=1).values\ny = ghost_goblin.type.values\n\nKPCA = KernelPCA(n_components=2, kernel=\"rbf\")\nghost_goblin_KPCA= KPCA.fit(X,y)\n\nghost_goblin_transf = ghost_goblin_KPCA.transform(X)\n\nplot_KPCA(ghost_goblin, ghost_goblin_transf, labels={\"Ghost\":0, \"Ghoblin\":2})",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "yeee again!",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Ghoul - Goblin",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = ghoul_goblin.drop([\"id\", \"color\", \"type\"], axis=1).values\ny = ghoul_goblin.type.values\n\nKPCA = KernelPCA(n_components=2, kernel=\"rbf\", gamma=3)\nghoul_goblin_KPCA= KPCA.fit(X,y)\n\nghoul_goblin_transf = ghoul_goblin_KPCA.transform(X)\n\nplot_KPCA(ghoul_goblin, ghoul_goblin_transf, labels={\"Ghoul\":1, \"Ghoblin\":2})",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Fucking Goblins wannabe Ghouls.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Use the projection as new features.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ghost_ghoul[\"KPCA_0\"] = ghost_ghoul_transf[:,0]\nghost_ghoul[\"KPCA_1\"] = ghost_ghoul_transf[:,1]\n\nghost_goblin[\"KPCA_0\"] = ghost_goblin_transf[:,0]\nghost_goblin[\"KPCA_1\"] = ghost_goblin_transf[:,1]\n\nghoul_goblin[\"KPCA_0\"] = ghoul_goblin_transf[:,0]\nghoul_goblin[\"KPCA_1\"] = ghoul_goblin_transf[:,1]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Neural Nets 1vs1",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def neural_net(X_train, y_train, X_test, layers=[1024], dropout=0.8, n_epoch=30):\n    \n    if isinstance(X_train, pd.DataFrame):\n        X_train = X_train.values\n        \n    if isinstance(y_train, pd.DataFrame):\n        y_train = y_train.values\n        \n    if isinstance(X_test, pd.DataFrame):\n        X_test = X_test.values\n        \n    with tf.Graph().as_default():\n\n        net = tflearn.input_data(shape=[None, X_train.shape[1]])\n        for layer_size in layers:            \n            net = tflearn.fully_connected(net, layer_size,\n                                          activation='relu',\n                                          weights_init='xavier',\n                                          regularizer='L2')\n            net = tflearn.dropout(net, dropout)\n        net = tflearn.fully_connected(net, y_train.shape[1], activation='softmax')\n        net = tflearn.regression(net)\n\n        model = tflearn.DNN(net, tensorboard_verbose=0)\n        model.fit(X_train, y_train, validation_set=0.2, n_epoch=n_epoch)\n\n        probs = np.array(model.predict(X_test))    \n        \n    return probs",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Ghost-Ghoul",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train = ghost_ghoul.drop([\"id\", \"color\", \"type\"], axis=1)\ny_train = pd.get_dummies(ghost_ghoul[\"type\"])\nX_test = test.drop([\"id\", \"color\"], axis=1)\n\n# Apply the KPCA transformer to test\ntransf = ghost_ghoul_KPCA.transform(X_test)\n\nX_test[\"KPCA_0\"] = transf[:,0]\nX_test[\"KPCA_1\"] = transf[:,1]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ghost_ghoul_probs = neural_net(X_train, y_train, X_test, dropout=0.8, n_epoch=40)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Ghost-Goblin",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train = ghost_goblin.drop([\"id\", \"color\", \"type\"], axis=1)\ny_train = pd.get_dummies(ghost_goblin[\"type\"])\nX_test = test.drop([\"id\", \"color\"], axis=1)\n\n# Apply the KPCA transformer to test\ntransf = ghost_goblin_KPCA.transform(X_test)\n\nX_test[\"KPCA_0\"] = transf[:,0]\nX_test[\"KPCA_1\"] = transf[:,1]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ghost_goblin_probs = neural_net(X_train, y_train, X_test, layers=[512], dropout=0.8, n_epoch=60)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Ghoul-Goblin",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train = ghoul_goblin.drop([\"id\", \"color\", \"type\"], axis=1)\ny_train = pd.get_dummies(ghoul_goblin[\"type\"])\nX_test = test.drop([\"id\", \"color\"], axis=1)\n\n# Apply the KPCA transformer to test\ntransf = ghoul_goblin_KPCA.transform(X_test)\n\nX_test[\"KPCA_0\"] = transf[:,0]\nX_test[\"KPCA_1\"] = transf[:,1]",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "ghoul_goblin_probs = neural_net(X_train, y_train, X_test, dropout=0.5, n_epoch=40)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Vote",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "global_predictions =  np.zeros((X_test.values.shape[0], 3))\n\nglobal_predictions[:,[0,1]] += ghost_ghoul_probs\nglobal_predictions[:,[0,2]] += ghost_goblin_probs\nglobal_predictions[:,[1,2]] += ghoul_goblin_probs",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Plot global predictions on test set",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "test[\"global_pred\"] = np.argmax(global_predictions, axis=1).astype(\"str\")\n\ntest.loc[test.global_pred == \"0\", \"global_pred\"] = \"Ghost\"\ntest.loc[test.global_pred == \"1\", \"global_pred\"] = \"Ghoul\"\ntest.loc[test.global_pred == \"2\", \"global_pred\"] = \"Ghoblin\"",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "sns.pairplot(test.drop(\"id\",axis=1), hue=\"global_pred\", diag_kind=\"kde\")",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "submission[\"type\"] = test[\"global_pred\"] \nsubmission.to_csv(\"sub.csv\", index=False)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# TO BE CONTINUED",
      "metadata": {}
    }
  ]
}